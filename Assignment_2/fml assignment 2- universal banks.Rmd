---
title: "FML assignment 2"
author: "rishitha rapuri - 811283595"
date: "2023-09-29"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Summary

The goal of the assignment is to forecast, using KNN(k-Nearest Neighbors)Classification, if the loan offer will be accepted by Universal Bank's customers. The dataset includes customer demographic data as well as other cilent-related details. The dataset is first read, the necessary libraries are installed, and then unnecessary columns are deleted, category categories are turned to dummy variables, and the data is finally normalized. The dataset was then split into two sets, training and validation, each containing 60% and 40% of the total data. Using k-NN with k=1, a new customer was classified as either accepting or rejecting a loan offer. The best k value, which strikes a balance between overfitting and underfitting, was discovered by evaluating accuracy on the validation set, with k=3 being the best.


Problem Statement

Universal bank is a young bank growing rapidly in terms of overall customer acquisition. The majority of
these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this baserapidly in more loan business. In particular, it wants to explore ways of converting its liability customers topersonal loan customers.

A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over
9% success. This has encouraged the retail marketing department to devise smarter campaigns with better
target marketing. The goal is to use k-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign.
The file UniversalBank.csv contains data on 5000 customers. The data include customer demographic
information (age, income, etc.), the customer’s relationship with the bank (mortgage, securities account,etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.

Partition the data into training (60%) and validation (40%) sets




install “class”,“caret”,“e1071”

call the libraries “class”,“caret”,“e1071”
```{r}
library(class)

library(caret)


```


```{r}
library(e1071)
```


Read the bank csv file
```{r}
x <- read.csv("C://Users//rishi//OneDrive//Desktop//universal bank//UniversalBank.csv")
dim(x)

```

```{r}
head(x)
```

```{r}
t(t(names(x))) #transpose of the dataframe
```


Dropping "id" and "zip" attributes for the dataset
```{r}
newdata <-x[,-c(1,5)]
dim(newdata)
```
converting the education attribute from "int" to "char"

```{r}
newdata$Education <- as.factor(newdata$Education)

```


creating dummy variables for the “education” attribute

```{r}

dummy <- dummyVars(~.,data=newdata)
the_data <- as.data.frame(predict(dummy,newdata))
```

Setting the seed as we need to run the function again and partitioning the data into training (60%) and validation (40%) sets.

```{r}
set.seed(1)
train.data <- sample(row.names(the_data), 0.6*dim(the_data)[1])
valid.data <- setdiff(row.names(the_data),train.data)
train <- the_data[train.data,]
valid <- the_data[valid.data,]
t(t(names(train)))
```
```{r}
summary(train)
```

```{r}
print(paste("The size of the training dataset is:",nrow(train)))
```


```{r}
summary(valid)
```


```{r}
print(paste("The size of the validation dataset is:",nrow(valid)))

```


Normalizing the dataset

```{r}
train.norm <- train[,-10]
valid.norm <- valid[,-10]
norm <- preProcess(train[,-10],method=c("center","scale"))
train.norm <- predict(norm,train[,-10])
valid.norm <- predict(norm,valid[,-10])

```

QUESTIONS

Consider the following customer:

1. Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities
Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform
a k-NN classification with all predictors except ID and ZIP code using k = 1.
Remember to transform categorical predictors with more than two categories
into dummy variables first. Specify the success class as 1 (loan acceptance), and
use the default cutoff value of 0.5. How would this customer be classified

Creating new customer data

```{r}
new.customer <- data.frame(
Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education.1 = 0,
Education.2 = 1,
Education.3 = 0,
Mortgage = 0,
Securities.Account = 0,
CD.Account = 0,
Online = 1,
CreditCard = 1)

# Normalize the new customer dataset
cust.norm <- predict(norm, new.customer)




```

Performing the kNN classification

```{r}
prediction <- class::knn(train = train.norm,
test = cust.norm,
cl = train$Personal.Loan, k = 1)
prediction

```

2.What is a choice of k that balances between over fitting and ignoring the predictor information?

```{r}
# Calculate the accuracy for each value of k
# Set the range of k values to consider
accuracy <- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
kn <- class::knn(train = train.norm,
test = valid.norm,
cl = train$Personal.Loan, k = i)
accuracy[i, 2] <- confusionMatrix(kn,
as.factor(valid$Personal.Loan),positive = "1")$overall[1]
}
which(accuracy[,2] == max(accuracy[,2]))

```


```{r}
accuracy
```

The best performing k in the range of 1 to 15 is 3.This k balances overfitting and ignoring predictions, and is the most accurate for 3

```{r}
plot(accuracy$k,accuracy$overallaccuracy)
```

### 3. Show the confusion matrix for the validation data that results from using the best k.


confusion matrix
```{r}
pred <- class::knn(train = train.norm,
test = valid.norm,
cl = train$Personal.Loan, k=3)
confusionMatrix(pred,as.factor(valid$Personal.Loan))

```

4. Consider the following customer: Age = 40, Experience = 10, Income =
84,Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3
= 0,Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and
CreditCard = 1. Classify the customer using the best k.


Now creating the 2nd new customer dataset

```{r}
customer2.df <- data.frame(
Age = 40,
Experience = 10,
Income = 84,
Family = 2,
CCAvg = 2,
Education.1 = 0,
Education.2 = 1,
Education.3 = 0,
Mortgage = 0,
Securities.Account = 0,
CD.Account = 0,
Online = 1,
CreditCard = 1)

#Normalizing the 2nd customer dataset
cust_norm2 <- predict(norm , customer2.df)
```

Question-5: Repeating the process by partitioning the data into three parts -50%, 30%, 20%,Apply the k-NN method with the k chosen above. Compare the confusion matrix of the test set with that of the training and validation sets. Comment on the differences and their reason.

```{r}
set.seed(400)
Train_Index <- sample(row.names(the_data), .5*dim(the_data)[1])#create train index
```



```{r}
#create validation index
Val_Index <- sample(setdiff(row.names(the_data),Train_Index),.3*dim(the_data)[1])
Test_Index =setdiff(row.names(the_data),union(Train_Index,Val_Index))#create test index
train.df <- the_data[Train_Index,]
cat("The size of the new training dataset is:", nrow(train.df))
```


```{r}
valid.df <- the_data[Val_Index, ]
cat("The size of the new validation dataset is:", nrow(valid.df))

```

```{r}
test.df <- the_data[Test_Index, ]
cat("The size of the new test dataset is:", nrow(test.df))
```

Data Normalizing
```{r}
norm.values <- preProcess(train.df[, -10], method=c("center", "scale"))
train.df.norm <- predict(norm.values, train.df[, -10])
valid.df.norm <- predict(norm.values, valid.df[, -10])
test.df.norm <- predict(norm.values, test.df[,-10])
```


Performing kNN and creating confusion matrix on training, testing, validation data
```{r}
pred3 <- class::knn(train = train.df.norm,
test = test.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred3,as.factor(test.df$Personal.Loan))

```


```{r}
pred4 <- class::knn(train = train.df.norm,
test = valid.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred4,as.factor(valid.df$Personal.Loan))
```


```{r}
pred4 <- class::knn(train = train.df.norm,
test = valid.df.norm,
cl = train.df$Personal.Loan, k=3)
confusionMatrix(pred4,as.factor(valid.df$Personal.Loan))

```


```{r}
